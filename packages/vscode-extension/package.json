{
  "name": "lingyun",
  "displayName": "LingYun",
  "description": "Agentic AI assistant for VS Code",
  "version": "2.0.1",
  "publisher": "mzbac",
  "icon": "images/icon.png",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/mzbac/lingyun"
  },
  "engines": {
    "vscode": "^1.93.0"
  },
  "categories": [
    "Machine Learning",
    "Other"
  ],
  "keywords": [
    "lingyun",
    "ai",
    "agent",
    "tools",
    "automation"
  ],
  "activationEvents": [],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "lingyun.start",
        "title": "LingYun: Start Task",
        "icon": "$(play)"
      },
      {
        "command": "lingyun.abort",
        "title": "LingYun: Abort"
      },
      {
        "command": "lingyun.clear",
        "title": "LingYun: Clear History"
      },
      {
        "command": "lingyun.undo",
        "title": "LingYun: Undo"
      },
      {
        "command": "lingyun.redo",
        "title": "LingYun: Redo"
      },
      {
        "command": "lingyun.clearSavedSessions",
        "title": "LingYun: Clear Saved Sessions"
      },
      {
        "command": "lingyun.compactSession",
        "title": "LingYun: Compact Session"
      },
      {
        "command": "lingyun.showLogs",
        "title": "LingYun: Show Logs"
      },
      {
        "command": "lingyun.listTools",
        "title": "LingYun: List Tools",
        "icon": "$(list-unordered)"
      },
      {
        "command": "lingyun.createToolsConfig",
        "title": "LingYun: Create Workspace Tools Config"
      },
      {
        "command": "lingyun.runTool",
        "title": "LingYun: Run Tool Manually"
      }
    ],
    "viewsContainers": {
      "activitybar": [
        {
          "id": "lingyun",
          "title": "LingYun",
          "icon": "media/icon.svg"
        }
      ]
    },
    "views": {
      "lingyun": [
        {
          "type": "webview",
          "id": "lingyun.chatView",
          "name": "AGENT",
          "icon": "media/icon.svg"
        }
      ]
    },
    "menus": {
      "view/title": [
        {
          "command": "lingyun.listTools",
          "when": "view == lingyun.chatView",
          "group": "navigation"
        }
      ]
    },
    "keybindings": [
      {
        "command": "lingyun.start",
        "key": "ctrl+shift+.",
        "mac": "cmd+shift+."
      }
    ],
    "configuration": {
      "title": "LingYun",
      "properties": {
        "lingyun.llmProvider": {
          "type": "string",
          "default": "copilot",
          "enum": [
            "copilot",
            "openaiCompatible"
          ],
          "description": "LLM provider backend to use"
        },
        "lingyun.model": {
          "type": "string",
          "default": "gpt-4o",
          "description": "Model ID to use (populated by the in-extension model picker)"
        },
        "lingyun.mode": {
          "type": "string",
          "default": "build",
          "enum": [
            "build",
            "plan"
          ],
          "description": "Agent mode: build can modify the workspace, plan is read-only (tools restricted)"
        },
        "lingyun.temperature": {
          "type": "number",
          "default": 0,
          "description": "Sampling temperature for the model (0.0 = deterministic). Increase for more creative responses."
        },
        "lingyun.llm.maxRetries": {
          "type": "number",
          "default": 2,
          "description": "Retry count for transient LLM request failures (network errors, overload, etc.). Set to 0 to disable retries."
        },
        "lingyun.llm.timeoutMs": {
          "type": "number",
          "default": 0,
          "description": "LLM request timeout in milliseconds (0 = no timeout). If you see 'The operation was aborted due to timeout', increase this value or set it to 0."
        },
        "lingyun.toolTimeoutMs": {
          "type": "number",
          "default": 0,
          "description": "Tool execution timeout in milliseconds (0 = no timeout). Applies to all tools."
        },
        "lingyun.tools.read.maxLines": {
          "type": "number",
          "default": 300,
          "minimum": 1,
          "description": "Maximum number of lines the Read tool can return per call. Files longer than this require using offset/limit (or LSP) to avoid overflowing the context window."
        },
        "lingyun.tools.bash.backgroundTtlMs": {
          "type": "number",
          "default": 600000,
          "minimum": 0,
          "description": "Time-to-live (ms) for background bash commands (0 disables auto-stop). Helps prevent long-running dev servers from accumulating in the background."
        },
        "lingyun.tools.bash.backgroundCaptureMs": {
          "type": "number",
          "default": 2000,
          "minimum": 0,
          "description": "When background bash commands are used, wait up to this many milliseconds to capture startup output for the tool result (0 disables capture and returns immediately)."
        },
        "lingyun.tools.bash.backgroundCaptureLines": {
          "type": "number",
          "default": 50,
          "minimum": 0,
          "description": "When background bash commands are used, maximum number of startup output lines to include in the tool result."
        },
        "lingyun.openaiCompatible.baseURL": {
          "type": "string",
          "default": "",
          "description": "Base URL for an OpenAI-compatible server (include /v1), e.g. http://localhost:8080/v1"
        },
        "lingyun.openaiCompatible.defaultModelId": {
          "type": "string",
          "default": "",
          "description": "Fallback model id for the OpenAI-compatible provider if lingyun.model is unset"
        },
        "lingyun.openaiCompatible.modelDisplayNames": {
          "type": "object",
          "default": {},
          "description": "Optional mapping from model id to a friendly display name",
          "additionalProperties": {
            "type": "string"
          }
        },
        "lingyun.openaiCompatible.apiKeyEnv": {
          "type": "string",
          "default": "OPENAI_API_KEY",
          "description": "Environment variable name that contains the API key (if your server requires auth)"
        },
        "lingyun.openaiCompatible.maxTokens": {
          "type": "number",
          "default": 32000,
          "description": "Max output tokens to request from an OpenAI-compatible server (sent as max_tokens). Increase if responses cut off early."
        },
        "lingyun.modelLimits": {
          "type": "object",
          "default": {},
          "description": "Per-model token limits used for context tracking and auto-compaction. Example: { \"gpt-4o\": { \"context\": 128000, \"output\": 32000 } }",
          "additionalProperties": {
            "type": "object",
            "properties": {
              "context": {
                "type": "number",
                "description": "Maximum context (input+output) tokens for this model"
              },
              "output": {
                "type": "number",
                "description": "Maximum output tokens for this model (used to reserve output budget during overflow detection)"
              }
            },
            "required": [
              "context"
            ]
          }
        },
        "lingyun.compaction.auto": {
          "type": "boolean",
          "default": true,
          "description": "Automatically compact the session when the context window would overflow"
        },
        "lingyun.compaction.prune": {
          "type": "boolean",
          "default": true,
          "description": "Prune old tool outputs from the prompt context before running a full compaction summary"
        },
        "lingyun.compaction.pruneProtectTokens": {
          "type": "number",
          "default": 40000,
          "description": "Keep at least this many recent tool-output tokens before pruning older tool outputs"
        },
        "lingyun.compaction.pruneMinimumTokens": {
          "type": "number",
          "default": 20000,
          "description": "Only prune tool outputs if at least this many tokens would be cleared"
        },
        "lingyun.autoApprove": {
          "type": "boolean",
          "default": false,
          "description": "Auto-approve all tool calls (not recommended)"
        },
        "lingyun.planFirst": {
          "type": "boolean",
          "default": true,
          "description": "Generate and review a plan before executing a new task"
        },
        "lingyun.showThinking": {
          "type": "boolean",
          "default": true,
          "description": "Show model 'thinking' output (e.g. <think> blocks) as a separate stream in the chat UI"
        },
        "lingyun.sessions.persist": {
          "type": "boolean",
          "default": true,
          "description": "Persist chat sessions to disk (workspace-scoped) so they can be restored after restarting VS Code"
        },
        "lingyun.sessions.maxSessions": {
          "type": "number",
          "default": 20,
          "description": "Maximum number of persisted sessions to keep (oldest pruned first)"
        },
        "lingyun.sessions.maxSessionBytes": {
          "type": "number",
          "default": 2000000,
          "description": "Maximum size per persisted session in bytes (oldest messages truncated first)"
        },
        "lingyun.toolFilter": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Only use tools matching these patterns (e.g., 'read', 'glob', 'workspace.deploy')"
        },
        "lingyun.env": {
          "type": "object",
          "default": {},
          "description": "Environment variables for workspace tools. Use ${env:VAR} in tool configs to reference these.",
          "additionalProperties": {
            "type": "string"
          }
        },
        "lingyun.instructions": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Additional instruction files or glob patterns to include in the system prompt. Relative patterns are matched from the active file's directory and each parent directory up to the workspace git root."
        },
        "lingyun.skills.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable skill discovery and the built-in skill tool (skill.list/skill.load)."
        },
        "lingyun.skills.paths": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            ".lingyun/skills",
            ".claude/skills",
            ".opencode/skill",
            ".opencode/skills",
            "~/.config/lingyun/skills",
            "~/.codex/skills",
            "~/.claude/skills"
          ],
          "description": "Directories to search for SKILL.md files (workspace-relative or absolute; supports ~). External directories are ignored unless lingyun.security.allowExternalPaths is enabled."
        },
        "lingyun.skills.maxPromptSkills": {
          "type": "number",
          "default": 50,
          "minimum": 0,
          "description": "Maximum number of skills to include in the system prompt (0 disables the skills section)."
        },
        "lingyun.skills.maxInjectSkills": {
          "type": "number",
          "default": 5,
          "minimum": 1,
          "description": "Maximum number of referenced skills to auto-inject per user message."
        },
        "lingyun.skills.maxInjectChars": {
          "type": "number",
          "default": 20000,
          "minimum": 1,
          "description": "Maximum characters to inject from each referenced skill file."
        },
        "lingyun.plugins": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Additional plugin modules to load (file URLs, paths, or module specifiers). Plugins can register hooks to transform prompts, tool calls, permissions, and outputs."
        },
        "lingyun.plugins.autoDiscover": {
          "type": "boolean",
          "default": true,
          "description": "Automatically discover workspace plugins under <workspace>/<plugins.workspaceDir>/plugin/*.js (also checks parent directories up to the git root)."
        },
        "lingyun.plugins.workspaceDir": {
          "type": "string",
          "default": ".lingyun",
          "description": "Workspace directory name used for auto-discovered plugins (contains plugin/)."
        },
        "lingyun.security.allowExternalPaths": {
          "type": "boolean",
          "default": false,
          "description": "Allow tools to access paths outside the current workspace. When disabled, external paths are always blocked (even if approvals/autoApprove are enabled) and shell commands/scripts that reference paths outside the workspace are blocked."
        },
        "lingyun.debug.llm": {
          "type": "boolean",
          "default": false,
          "description": "Log redacted LLM request/response metadata to the LingYun output channel (no prompts/URLs). Useful for debugging cut-off or missing tool calls."
        },
        "lingyun.debug.tools": {
          "type": "boolean",
          "default": false,
          "description": "Log tool execution/approval metadata to the LingYun output channel (no prompts/URLs). Useful for debugging tool failures and permission prompts."
        },
        "lingyun.debug.plugins": {
          "type": "boolean",
          "default": false,
          "description": "Log plugin discovery/loading events to the LingYun output channel. Useful when debugging .lingyun/plugin hooks."
        }
      }
    },
    "jsonValidation": [
      {
        "fileMatch": ".vscode/agent-tools.json",
        "url": "./schemas/agent-tools.schema.json"
      }
    ]
  },
  "scripts": {
    "vscode:prepublish": "pnpm run bundle",
    "build": "pnpm run bundle",
    "clean": "node scripts/clean.js",
    "compile": "pnpm run clean && tsc -p ./",
    "bundle": "pnpm run clean && node scripts/bundle.js",
    "watch": "tsc -watch -p ./",
    "lint": "eslint src --ext ts",
    "test": "pnpm run compile && node ./dist/test/runTest.js",
    "test:unit": "pnpm run compile && mocha ./dist/test/suite/*.test.js",
    "test:manual": "pnpm run compile && node scripts/test-manual.js",
    "sdk:build": "pnpm --filter @lingyun/agent-sdk build",
    "sdk:test": "pnpm --filter @lingyun/agent-sdk test",
    "sdk:test:e2e": "pnpm --filter @lingyun/agent-sdk test:e2e",
    "verify": "node scripts/verify.js",
    "package": "vsce package --no-dependencies",
    "publish": "vsce publish --no-dependencies"
  },
  "dependencies": {
    "@lingyun/core": "workspace:*",
    "@ai-sdk/openai-compatible": "^2.0.2",
    "ai": "^6.0.6",
    "diff": "^7.0.0",
    "undici": "^7.18.2",
    "zod": "^4.1.8"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.2",
    "@types/diff": "^7.0.0",
    "@types/mocha": "^10.0.10",
    "@types/node": "^20.11.16",
    "@types/vscode": "^1.93.0",
    "@typescript-eslint/eslint-plugin": "^8.50.0",
    "@typescript-eslint/parser": "^8.50.0",
    "@vscode/test-electron": "^2.5.2",
    "@vscode/vsce": "^2.22.0",
    "esbuild": "^0.25.0",
    "eslint": "^9.39.2",
    "glob": "^13.0.0",
    "mocha": "^11.7.5",
    "typescript": "^5.3.3",
    "typescript-eslint": "^8.50.0"
  },
  "extensionDependencies": [],
  "capabilities": {
    "virtualWorkspaces": true,
    "untrustedWorkspaces": {
      "supported": "limited",
      "description": "Shell commands are disabled in untrusted workspaces"
    }
  }
}
