{
  "name": "lingyun",
  "displayName": "LingYun",
  "description": "Agentic AI assistant for VS Code",
  "version": "2.0.20",
  "publisher": "mzbac",
  "icon": "images/icon.png",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/mzbac/lingyun"
  },
  "engines": {
    "vscode": "^1.93.0"
  },
  "categories": [
    "Machine Learning",
    "Other"
  ],
  "keywords": [
    "lingyun",
    "ai",
    "agent",
    "tools",
    "automation"
  ],
  "activationEvents": [],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "lingyun.start",
        "title": "LingYun: Start Task",
        "icon": "$(play)"
      },
      {
        "command": "lingyun.abort",
        "title": "LingYun: Abort"
      },
      {
        "command": "lingyun.clear",
        "title": "LingYun: Clear History"
      },
      {
        "command": "lingyun.undo",
        "title": "LingYun: Undo"
      },
      {
        "command": "lingyun.redo",
        "title": "LingYun: Redo"
      },
      {
        "command": "lingyun.clearSavedSessions",
        "title": "LingYun: Clear Saved Sessions"
      },
      {
        "command": "lingyun.compactSession",
        "title": "LingYun: Compact Session"
      },
      {
        "command": "lingyun.showLogs",
        "title": "LingYun: Show Logs"
      },
      {
        "command": "lingyun.listTools",
        "title": "LingYun: List Tools",
        "icon": "$(list-unordered)"
      },
      {
        "command": "lingyun.createToolsConfig",
        "title": "LingYun: Create Workspace Tools Config"
      },
      {
        "command": "lingyun.runTool",
        "title": "LingYun: Run Tool Manually"
      }
    ],
    "viewsContainers": {
      "activitybar": [
        {
          "id": "lingyun",
          "title": "LingYun",
          "icon": "media/icon.svg"
        }
      ]
    },
    "views": {
      "lingyun": [
        {
          "type": "webview",
          "id": "lingyun.chatView",
          "name": "AGENT",
          "icon": "media/icon.svg"
        }
      ]
    },
    "menus": {
      "view/title": [
        {
          "command": "lingyun.listTools",
          "when": "view == lingyun.chatView",
          "group": "navigation"
        }
      ]
    },
    "keybindings": [
      {
        "command": "lingyun.start",
        "key": "ctrl+shift+.",
        "mac": "cmd+shift+."
      }
    ],
    "configuration": {
      "title": "LingYun",
      "properties": {
        "lingyun.llmProvider": {
          "type": "string",
          "default": "copilot",
          "enum": [
            "copilot",
            "openaiCompatible"
          ],
          "description": "LLM provider backend to use"
        },
        "lingyun.model": {
          "type": "string",
          "default": "gpt-4o",
          "description": "Model ID to use (populated by the in-extension model picker)"
        },
        "lingyun.copilot.reasoningEffort": {
          "type": "string",
          "default": "xhigh",
          "enum": [
            "",
            "low",
            "medium",
            "high",
            "xhigh"
          ],
          "description": "Copilot-only: reasoning effort hint to send for GPT-5 family models. Set to empty to disable."
        },
        "lingyun.subagents.model": {
          "type": "string",
          "default": "",
          "description": "Optional model ID to use for subagents spawned via the task tool (falls back to lingyun.model when empty)."
        },
        "lingyun.subagents.explorePrepass.enabled": {
          "type": "boolean",
          "default": false,
          "description": "Automatically run the explore subagent before each user turn to gather lightweight workspace context (reduces main agent prompt bloat)."
        },
        "lingyun.subagents.explorePrepass.maxChars": {
          "type": "number",
          "default": 8000,
          "description": "Maximum characters of explore-subagent output to inject into the main agent context."
        },
        "lingyun.subagents.task.maxOutputChars": {
          "type": "number",
          "default": 8000,
          "minimum": 500,
          "description": "Maximum characters of task subagent output to inject into the main agent context (the full subagent session is still saved separately)."
        },
        "lingyun.mode": {
          "type": "string",
          "default": "build",
          "enum": [
            "build",
            "plan"
          ],
          "description": "Agent mode: build can modify the workspace, plan is read-only (tools restricted)"
        },
        "lingyun.temperature": {
          "type": "number",
          "default": 0,
          "description": "Sampling temperature for the model (0.0 = deterministic). Increase for more creative responses."
        },
        "lingyun.llm.maxRetries": {
          "type": "number",
          "default": 2,
          "description": "Retry count for transient LLM request failures (network errors, overload, etc.). Set to 0 to disable retries."
        },
        "lingyun.llm.timeoutMs": {
          "type": "number",
          "default": 0,
          "description": "LLM request timeout in milliseconds (0 = no timeout). If you see 'The operation was aborted due to timeout', increase this value or set it to 0."
        },
        "lingyun.toolTimeoutMs": {
          "type": "number",
          "default": 0,
          "description": "Tool execution timeout in milliseconds (0 = no timeout). Applies to all tools."
        },
        "lingyun.tools.read.maxLines": {
          "type": "number",
          "default": 300,
          "minimum": 1,
          "description": "Maximum number of lines the Read tool can return per call. Files longer than this require using offset/limit (or LSP) to avoid overflowing the context window."
        },
        "lingyun.tools.bash.backgroundTtlMs": {
          "type": "number",
          "default": 600000,
          "minimum": 0,
          "description": "Time-to-live (ms) for background bash commands (0 disables auto-stop). Helps prevent long-running dev servers from accumulating in the background."
        },
        "lingyun.tools.bash.backgroundCaptureMs": {
          "type": "number",
          "default": 2000,
          "minimum": 0,
          "description": "When background bash commands are used, wait up to this many milliseconds to capture startup output for the tool result (0 disables capture and returns immediately)."
        },
        "lingyun.tools.bash.backgroundCaptureLines": {
          "type": "number",
          "default": 50,
          "minimum": 0,
          "description": "When background bash commands are used, maximum number of startup output lines to include in the tool result."
        },
        "lingyun.tools.workspaceShell.timeoutMs": {
          "type": "number",
          "default": 60000,
          "minimum": 0,
          "description": "Timeout in milliseconds for workspace-defined shell tools (0 disables timeout). This helps prevent long-running scripts from blocking the turn."
        },
        "lingyun.tools.http.timeoutMs": {
          "type": "number",
          "default": 30000,
          "minimum": 0,
          "description": "Timeout in milliseconds for workspace-defined HTTP tools (0 disables timeout)."
        },
        "lingyun.openaiCompatible.baseURL": {
          "type": "string",
          "default": "",
          "description": "Base URL for an OpenAI-compatible server (include /v1), e.g. http://localhost:8080/v1"
        },
        "lingyun.openaiCompatible.defaultModelId": {
          "type": "string",
          "default": "",
          "description": "Fallback model id for the OpenAI-compatible provider if lingyun.model is unset"
        },
        "lingyun.openaiCompatible.modelDisplayNames": {
          "type": "object",
          "default": {},
          "description": "Optional mapping from model id to a friendly display name",
          "additionalProperties": {
            "type": "string"
          }
        },
        "lingyun.openaiCompatible.apiKeyEnv": {
          "type": "string",
          "default": "OPENAI_API_KEY",
          "description": "Environment variable name that contains the API key (if your server requires auth)"
        },
        "lingyun.openaiCompatible.maxTokens": {
          "type": "number",
          "default": 32000,
          "description": "Max output tokens to request from an OpenAI-compatible server (sent as max_tokens). Increase if responses cut off early."
        },
        "lingyun.modelLimits": {
          "type": "object",
          "default": {},
          "description": "Per-model token limits used for context tracking and auto-compaction. Example: { \"gpt-4o\": { \"context\": 128000, \"output\": 32000 } }",
          "additionalProperties": {
            "type": "object",
            "properties": {
              "context": {
                "type": "number",
                "description": "Maximum context (input+output) tokens for this model"
              },
              "output": {
                "type": "number",
                "description": "Maximum output tokens for this model (used to reserve output budget during overflow detection)"
              }
            },
            "required": [
              "context"
            ]
          }
        },
        "lingyun.compaction.auto": {
          "type": "boolean",
          "default": true,
          "description": "Automatically compact the session when the context window would overflow"
        },
        "lingyun.compaction.prune": {
          "type": "boolean",
          "default": true,
          "description": "Prune old tool outputs from the prompt context before running a full compaction summary"
        },
        "lingyun.compaction.pruneProtectTokens": {
          "type": "number",
          "default": 40000,
          "description": "Keep at least this many recent tool-output tokens before pruning older tool outputs"
        },
        "lingyun.compaction.pruneMinimumTokens": {
          "type": "number",
          "default": 20000,
          "description": "Only prune tool outputs if at least this many tokens would be cleared"
        },
        "lingyun.compaction.toolOutputMode": {
          "type": "string",
          "default": "afterToolCall",
          "enum": [
            "onCompaction",
            "afterToolCall"
          ],
          "description": "When to compact tool outputs in the model prompt. onCompaction only prunes outputs during session compaction; afterToolCall prunes tool outputs after the model has seen them once."
        },
        "lingyun.compaction.memoryFlush.enabled": {
          "type": "boolean",
          "default": false,
          "description": "Before compaction, write a durable memory snapshot to MEMORY.md or memory/*.md"
        },
        "lingyun.compaction.memoryFlush.filePath": {
          "type": "string",
          "default": "MEMORY.md",
          "description": "Target memory file for compaction-time memory flush (MEMORY.md or memory/*.md)"
        },
        "lingyun.compaction.memoryFlush.maxChars": {
          "type": "number",
          "default": 8000,
          "description": "Maximum characters to write during compaction memory flush"
        },
        "lingyun.memory.cache.maxEntries": {
          "type": "number",
          "default": 200,
          "description": "Maximum number of cached memory files kept in-memory for faster memory_search/memory_get"
        },
        "lingyun.memory.cache.maxSnippetChars": {
          "type": "number",
          "default": 1200,
          "description": "Maximum snippet length returned by memory_search"
        },
        "lingyun.memory.get.maxLines": {
          "type": "number",
          "default": 80,
          "description": "Maximum number of lines returned by memory_get"
        },
        "lingyun.autoApprove": {
          "type": "boolean",
          "default": false,
          "description": "Auto-approve all tool calls (not recommended)"
        },
        "lingyun.planFirst": {
          "type": "boolean",
          "default": true,
          "description": "Generate and review a plan before executing a new task"
        },
        "lingyun.showThinking": {
          "type": "boolean",
          "default": true,
          "description": "Show model 'thinking' output (e.g. <think> blocks) as a separate stream in the chat UI"
        },
        "lingyun.sessions.persist": {
          "type": "boolean",
          "default": true,
          "description": "Persist chat sessions to disk (workspace-scoped) so they can be restored after restarting VS Code"
        },
        "lingyun.sessions.maxSessions": {
          "type": "number",
          "default": 20,
          "description": "Maximum number of persisted sessions to keep (oldest pruned first)"
        },
        "lingyun.sessions.maxSessionBytes": {
          "type": "number",
          "default": 2000000,
          "description": "Maximum size per persisted session in bytes (oldest messages truncated first)"
        },
        "lingyun.toolFilter": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Only use tools matching these patterns (e.g., 'read', 'glob', 'workspace.deploy')"
        },
        "lingyun.env": {
          "type": "object",
          "default": {},
          "description": "Environment variables for workspace tools. Use ${env:VAR} in tool configs to reference these.",
          "additionalProperties": {
            "type": "string"
          }
        },
        "lingyun.instructions": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Additional instruction files or glob patterns to include in the system prompt. Relative patterns are matched from the active file's directory and each parent directory up to the workspace git root."
        },
        "lingyun.skills.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable skill discovery and the built-in skill tool (skill.list/skill.load)."
        },
        "lingyun.skills.paths": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            ".lingyun/skills",
            ".claude/skills",
            ".opencode/skill",
            ".opencode/skills",
            "~/.config/lingyun/skills",
            "~/.codex/skills",
            "~/.claude/skills"
          ],
          "description": "Directories to search for SKILL.md files (workspace-relative or absolute; supports ~). External directories are ignored unless lingyun.security.allowExternalPaths is enabled."
        },
        "lingyun.skills.maxPromptSkills": {
          "type": "number",
          "default": 50,
          "minimum": 0,
          "description": "Maximum number of skills to include in the system prompt (0 disables the skills section)."
        },
        "lingyun.skills.maxInjectSkills": {
          "type": "number",
          "default": 5,
          "minimum": 1,
          "description": "Maximum number of referenced skills to auto-inject per user message."
        },
        "lingyun.skills.maxInjectChars": {
          "type": "number",
          "default": 20000,
          "minimum": 1,
          "description": "Maximum characters to inject from each referenced skill file."
        },
        "lingyun.plugins": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Additional plugin modules to load (file URLs, paths, or module specifiers). Plugins can register hooks to transform prompts, tool calls, permissions, and outputs."
        },
        "lingyun.plugins.autoDiscover": {
          "type": "boolean",
          "default": false,
          "description": "Automatically discover workspace plugins under <workspace>/<plugins.workspaceDir>/plugin/*.js (also checks parent directories up to the git root). Plugin loading is disabled in untrusted workspaces."
        },
        "lingyun.plugins.workspaceDir": {
          "type": "string",
          "default": ".lingyun",
          "description": "Workspace directory name used for auto-discovered plugins (contains plugin/)."
        },
        "lingyun.security.allowExternalPaths": {
          "type": "boolean",
          "default": false,
          "description": "Allow tools to access paths outside the current workspace. When disabled, external paths are always blocked (even if approvals/autoApprove are enabled) and shell commands/scripts that reference paths outside the workspace are blocked."
        },
        "lingyun.security.blockGitPush": {
          "type": "boolean",
          "default": true,
          "description": "When enabled, the bash tool blocks `git push` to avoid accidentally pushing to remote. Disable this setting to allow the agent to run git push."
        },
        "lingyun.debug.llm": {
          "type": "boolean",
          "default": false,
          "description": "Log redacted LLM request/response metadata to the LingYun output channel (no prompts/URLs). Useful for debugging cut-off or missing tool calls."
        },
        "lingyun.debug.tools": {
          "type": "boolean",
          "default": false,
          "description": "Log tool execution/approval metadata to the LingYun output channel (no prompts/URLs). Useful for debugging tool failures and permission prompts."
        },
        "lingyun.debug.plugins": {
          "type": "boolean",
          "default": false,
          "description": "Log plugin discovery/loading events to the LingYun output channel. Useful when debugging .lingyun/plugin hooks."
        }
      }
    },
    "jsonValidation": [
      {
        "fileMatch": ".vscode/agent-tools.json",
        "url": "./schemas/agent-tools.schema.json"
      }
    ]
  },
  "scripts": {
    "vscode:prepublish": "pnpm run bundle",
    "build": "pnpm run bundle",
    "clean": "node scripts/clean.js",
    "compile": "pnpm --filter @kooka/core build && pnpm run clean && tsc -p ./",
    "bundle": "pnpm run clean && node scripts/bundle.js",
    "watch": "tsc -watch -p ./",
    "lint": "eslint src --ext ts",
    "test": "pnpm run compile && node ./dist/test/runTest.js",
    "test:unit": "pnpm run compile && mocha ./dist/test/suite/*.test.js",
    "test:manual": "pnpm run compile && node scripts/test-manual.js",
    "sdk:build": "pnpm --filter @kooka/agent-sdk build",
    "sdk:test": "pnpm --filter @kooka/agent-sdk test",
    "sdk:test:e2e": "pnpm --filter @kooka/agent-sdk test:e2e",
    "verify": "node scripts/verify.js",
    "package": "vsce package --no-dependencies",
    "publish": "vsce publish --no-dependencies"
  },
  "dependencies": {
    "@kooka/core": "workspace:*",
    "@ai-sdk/openai-compatible": "^2.0.30",
    "ai": "^6.0.86",
    "diff": "^7.0.0",
    "undici": "^7.18.2",
    "zod": "^4.1.8"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.2",
    "@ai-sdk/provider": "^3.0.2",
    "@ai-sdk/provider-utils": "^4.0.5",
    "@types/diff": "^7.0.0",
    "@types/mocha": "^10.0.10",
    "@types/node": "^20.11.16",
    "@types/vscode": "^1.93.0",
    "@typescript-eslint/eslint-plugin": "^8.50.0",
    "@typescript-eslint/parser": "^8.50.0",
    "@vscode/test-electron": "^2.5.2",
    "@vscode/vsce": "^2.22.0",
    "esbuild": "^0.25.0",
    "eslint": "^9.39.2",
    "glob": "^13.0.0",
    "mocha": "^11.7.5",
    "typescript": "^5.3.3",
    "typescript-eslint": "^8.50.0"
  },
  "extensionDependencies": [],
  "capabilities": {
    "virtualWorkspaces": true,
    "untrustedWorkspaces": {
      "supported": "limited",
      "description": "Shell commands are disabled in untrusted workspaces"
    }
  }
}
